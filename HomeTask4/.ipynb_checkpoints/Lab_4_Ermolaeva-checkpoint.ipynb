{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть коллекция состоит из D документов. Все слова занумерованы числами от 1 до\n",
    "V. Обозначим  $$ w_{dn} ∈ {1, ..., V } $$ \n",
    "— номер n-го слова в документе d.\n",
    "Предположим, что у нас имеется T различных тем, и $$ θ_{d} = (θ_{d1} , ..., θ_{dT} ) $$ — набор вероятностей, которые задают дискретное распределение на темах в документе d. Предположим так же, что при известной теме распределение слов в документе не зависит от самого документа, и $$ φ_{t} = (φ_{t1}, ..., φ_{tV}) $$ — набор вероятностей, которые задают дискретное распределение на словах в теме t(профиль темы). Обозначим $$ z_{dn} ∈ {1,..., T} $$ — номер темы, из которой сгенерировано n-ое слово в документе d.\n",
    "В данной модели функцию правдоподобия можно записать в виде\n",
    "$$ p(W |Θ, Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}}\\sum_{t=1}^{T}{θ_{dt}φ_{tw_{dn}}} $$, где $$ W = (w_{dn})_{dn} $$ - коллекция документов, $$ Θ = (θ_{dt})_{dt}  $$ — распределения на темах в документах, $$ Φ = (φ_{tv})_{tv} $$ — распределение слов на темах, $$ N_{d} $$  — число слов в документе d. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Почему такое распределение не принадлежит экспоненциальному классу распределений? \n",
    "\n",
    "Функция, принадлежащая экспоненциальному классу распределений, должна иметь следующий вид:\n",
    "$$ p(x|Θ) = h(x)g(θ)exp(a(θ)T(x)) $$\n",
    "\n",
    ",т.е в нашем случае\n",
    "$$ p(W| Θ, Φ) = h(W)g(θ, Ф)exp(a(θ, Ф)T(w)) $$\n",
    "\n",
    "Приведенную выше формулу для правдоподобия можно привести к следующему виду:\n",
    "$$ p(W |Θ, Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}} e^{ln {\\sum_{t=1}^{T}{θ_{dt}φ_{tw_{dn}}}}} $$\n",
    "\n",
    "Логарифм суммы в этой формуле нельзя представить в виде с разделенными переменными, относящимися только к W и только к Θ и Φ => такое распределение не принадлежит экспоненциальному классу распределений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем функцию правдоподобия, используя неизвестные значения Z (латентные переменные):\n",
    "    $$ p(W,Z|Θ, Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}}\\sum_{t=1}^{T}{θ_{dz_{dn}}φ_{z_{dn}w_{dn}}} $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Почему такое распределение не принадлежит экспоненциальному классу распределений?\n",
    "Ответ аналогичен: логарифм суммы не получится представить в виде произведения логарифмов только по W и только по  Θ и Φ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. \n",
    "Пусть $$ z^{'}_{dn} = (z^{'}_{dn, 1}, z^{'}_{dn,2}, ..., z^{'}_{dn, T}$$,где $$ z^{'}_{dn,i} = \\delta_{z_{dn}, i} $$ \n",
    "\n",
    "Тогда выражение можно представить в виде:\n",
    "$$ θ_{dz_{dn}}φ_{z_{dn}w_{dn}} = \\prod_{t=1}^{T} {(θ_{dt}φ_{tw_{dn}})}^{z^{'}_{dn, t}}$$ \n",
    "\n",
    "Тогда:\n",
    "$$ p(W,Z^{'}|Θ,Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}}\\prod_{t=1}^{T} {(θ_{dt}φ_{tw_{dn}})}^{z^{'}_{dn, t}} $$\n",
    "\n",
    "$$ p(W,Z^{'}|Θ,Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}}e^{\\sum_{t=1}^{T}ln{(θ_{dt}φ_{tw_{dn}})}^{z^{'}_{dn, t}}} $$\n",
    "\n",
    "$$ p(W,Z^{'}|Θ,Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}} e^{\\sum_{t=1}^{T} {z^{'}_{dn, t}} ln(θ_{dt}φ_{tw_{dn}})} $$\n",
    "\n",
    "$$ p(W,Z^{'}|Θ,Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}} e^{\\sum_{t=1}^{T} {z^{'}_{dn, t}} ln(θ_{dt}) + ln(φ_{tw_{dn}})} $$\n",
    "\n",
    "$$ p(W,Z^{'}|Θ,Φ) = \\prod_{d=1}^{D}\\prod_{n=1}^{N_{d}} e^{\\sum_{t=1}^{T} {z^{'}_{dn, t}}ln(θ_{dt})} e^{\\sum_{t=1}^{T} {z^{'}_{dn, t}} ln(φ_{tw_{dn}})} $$\n",
    "\n",
    "Следовательно, это распределение принадлежит экспоненциальному классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формулы для EM-алгоритма\n",
    "##### Е-шаг:\n",
    "$$ <z^{'}_{dn, i}> = p(z^{'}_{dn, i} = 1|W,Θ,Φ) = \\frac{ p(W,z^{'}_{dn, i} = 1 | Θ,Φ)}{\\sum_{t=1}^{T} p(W,z^{'}_{dn, i} = 1 | Θ,Φ) } $$\n",
    "\n",
    "$$ <z^{'}_{dn, i}> = \\frac{ p(w_{dn},z^{'}_{dn, i} = 1 | Θ,Φ)}{\\sum_{t=1}^{T} p(w_{dn},z^{'}_{dn, i} = 1 | Θ,Φ) } $$\n",
    "\n",
    "$$ <z^{'}_{dn, i}>  = \\frac{ p(w_{dn},z^{'}_{dn, i} = 1 | \\theta_{d},Φ)}{\\sum_{t=1}^{T} p(w_{dn},z^{'}_{dn, i} = 1 | \\theta_{d},Φ) } $$\n",
    "\n",
    "$$ <z^{'}_{dn, i}>  = \\frac{ p(w_{dn}|φ_{iw_{dn}}) p(i|\\theta_{d})}{\\sum_{t=1}^{T} p(w_{dn}|φ_{iw_{dn}}) p(i|\\theta_{d}) } $$\n",
    "\n",
    "$$ <z^{'}_{dn, i}> = \\frac{ φ_{iw_{dn}} \\theta_{di} } { \\sum_{t=1}^{T} φ_{tw_{dn}} \\theta_{dt} } $$\n",
    "\n",
    "##### M-шаг:\n",
    "$$ L = ln(p(W,Z'|\\Theta, Ф)) = \\sum_{d=1}^{D}\\sum_{n=1}^{N_{d}} \\sum_{t=1}^{T} {z^{'}_{dn, t}} (ln(θ_{dt}) + ln(φ_{tw_{dn}}))  $$\n",
    "\n",
    "$$ \\Lambda =  L + \\sum_{d=1}^{D} \\lambda_{d}(1 - \\sum_{t=1}^{T} \\theta_{dt}) + \n",
    "\\sum_{j=1}^{T}\\mu_{j}(1 - \\sum_{v=1}^{V} φ_{jv}) \\rightarrow max $$\n",
    "\n",
    "$$ \\frac{\\partial \\Lambda}{\\partial \\theta_{dt}} = \\sum_{dn,1}^{V} \\frac{<z^{'}_{dn, t}>}{\\theta_{dt}} - \\lambda_{d}  = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial \\Lambda}{\\partial \\lambda_{d}} = 1 - \\sum_{t=1}^{T} \\theta_{dt} = 0 $$ \n",
    "\n",
    "\n",
    "$$ \\theta_{dt}  = \\frac{ \\sum_{dn,1}^{V} <z^{'}_{dn, t}> } {N_{d}}$$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\Lambda}{\\partial φ_{tv}} =  \\sum_{d=1}^{D} \\sum_{dn,1}^{V} \\frac{<z^{'}_{dn, t}>I(w_{dn} = v)}{φ_{tv}} - \\mu_{d} = 0 $$\n",
    "\n",
    "$$ \\frac{\\partial \\Lambda}{\\partial \\mu_{t}} = 1 - \\sum_{v=1}^{V} φ_{tv} = 0 $$ \n",
    "\n",
    "$$ φ_{tv}  =  \\frac{ \\sum_{d=1}^{D} \\sum_{dn,1}^{V} <z^{'}_{dn, t}>I(w_{dn} = v)} { \\sum_{v^{'}}^{V} \\sum_{d=1}^{D} \\sum_{dn,1}^{V} <z^{'}_{dn, t}> I(w_{dn} = v^{'})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для одного слова в одном документе:\n",
    "$$ ln(p(w_{dn},Z|\\Theta, Ф)) =  ln(\\prod_{t=1}^{T} {(θ_{dt}φ_{tw_{dn}})}^{z^{'}_{dn, t}}) =  \n",
    "\\sum_{t=1}^{T} z^{'}_{dn, t}ln(θ_{dt}φ_{tw_{dn}}) = ln(\\sum_{t=1}^{T} z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}}) )$$\n",
    "\n",
    "Дополнительное распределение:\n",
    "$$ q(z'_{dn, t}) = q(z'_{dn, t} = 1) $$\n",
    "\n",
    "$$ ln(\\sum_{t=1}^{T} \\frac {z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}})} {q(z'_{dn, t})} q(z'_{dn, t}) ) = ln(E_{q}(\\frac {z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}})} {q(z'_{dn, t})}))  >=  E_{q} ln(\\frac {z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}})} {q(z'_{dn, t})})) = E_{q}(ln(z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}})) - ln(q(z'_{dn, t})))$$\n",
    "\n",
    "Нужно максимировать полученную нижнюю оценку с учетом условия $$ \\sum_{t=1}^{T} q(z'_{dn, t}) = 1$$\n",
    "\n",
    "$$ \\Lambda = \\sum_{t=1}^{T} (q(z'_{dn, t})ln(z^{'}_{dn, t}(θ_{dt}φ_{tw_{dn}})) \n",
    "- \\sum_{t=1}^{T} q(z'_{dn, t})ln(q(z^{'}_{dn, t})) + \\lambda(1 - \\sum_{t=1}^T q(z'_{dn, t})) $$\n",
    "\n",
    "$$ \\frac {\\partial \\Lambda}{\\partial q(z'_{dn, t})} = ln(z'_{dn, t}(\\theta_{dt}φ_{tw_{dn}})) - ln(q(z'_{dn,t})) -1 - \\lambda = 0 $$\n",
    "\n",
    "$$ q(z'_{dn,t}) = \\frac{ φ_{tw_{dn}} \\theta_{dt} } { \\sum_{k=1}^{T} φ_{kw_{dn}} \\theta_{dk} } $$\n",
    "\n",
    "\n",
    "Таким образом, полученное выше в Е шаге распределение есть вариационная нижняя оценка для $$ log p(W|\\Theta, \\Phi) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## d - номер документа, i - номер слова в документе\n",
    "def get_word_num(d, i, D_new):\n",
    "    # Return number of word in the dictionary\n",
    "    return D_new[d][i]\n",
    "\n",
    "def process_documents(D, dictionary):\n",
    "    D_new = []\n",
    "    for doc in D:\n",
    "        #print doc\n",
    "        D_new.append([dictionary.index(word) for word in doc if word in dictionary])\n",
    "    Nd = [len(doc) for doc in D_new]\n",
    "    return D_new, Nd\n",
    "    \n",
    "# D- коллекция документов\n",
    "# Theta0, Phi0 - начальное приближение для Theta и Phi\n",
    "def EM(D,T, dictionary, n_iterations=25, start_iterations = 1):\n",
    "    D_new, Nd = process_documents(D, dictionary)\n",
    "    V = len(dictionary)\n",
    "    estimates = []\n",
    "    for j in range(start_iterations):\n",
    "        ## Начальное приближение\n",
    "        Theta = np.random.random_sample((len(D),T))\n",
    "        Theta = Theta*1./(np.sum(Theta, axis = 1).reshape((Theta.shape[0], 1)))\n",
    "        Phi = np.random.random_sample((T,V))\n",
    "        Phi = Phi*1./(np.sum(Phi, axis = 1).reshape((Phi.shape[0],1)))\n",
    "        \n",
    "        # Z - вектор матриц размера(Nd * T)\n",
    "        Z = [np.zeros((Nd[d],T)) for d in range(len(D)) ] \n",
    "       \n",
    "        n = 0\n",
    "        staged_estimates = []\n",
    "        \n",
    "        while n <= n_iterations:\n",
    "            ### E-шаг\n",
    "            for d in range(len(D)):\n",
    "                for l in range(Nd[d]):\n",
    "                    word_num = get_word_num(d,l,D_new)\n",
    "                    Z[d][l] = Theta[d]*Phi[:, word_num].T*1. / (np.dot(Theta[d], Phi[:, word_num]))\n",
    "            ### M-шаг\n",
    "                Theta[d] = np.sum(Z[d], axis = 0)*1./Nd[d]\n",
    "            #print Theta    \n",
    "            Phi = np.zeros((T, V))\n",
    "            \n",
    "            for t in range(T):\n",
    "                for w in range(V):\n",
    "                    for d in range(len(D)):\n",
    "                        for l in range(Nd[d]):\n",
    "                            Phi[t][w] += (Z[d][l][t] * (get_word_num(d,l, D_new) == w))\n",
    "            Phi = Phi*1./(np.sum(Phi, axis = 1).reshape((Phi.shape[0], 1)))\n",
    "            \n",
    "            ## Подсчет вариационной нижней оценки\n",
    "            low_estimate = sum([Z[d][l][t]*(np.log(1.*Theta[d][t]*Phi[t][get_word_num(d, l, D_new)])) \\\n",
    "                                for d in range(len(D)) for l in range(Nd[d]) for t in range(T)])\n",
    "            staged_estimates.append(low_estimate)\n",
    "            n += 1\n",
    "            \n",
    "        estimates.append(staged_estimates)\n",
    "        \n",
    "    finals = [staged[-1] for staged in estimates]\n",
    "    index = np.argmax(finals)\n",
    "    return estimates, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'adventure',\n",
       " u'belles_lettres',\n",
       " u'editorial',\n",
       " u'fiction',\n",
       " u'government',\n",
       " u'hobbies',\n",
       " u'humor',\n",
       " u'learned',\n",
       " u'lore',\n",
       " u'mystery',\n",
       " u'news',\n",
       " u'religion',\n",
       " u'reviews',\n",
       " u'romance',\n",
       " u'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 17099\n"
     ]
    }
   ],
   "source": [
    "categories = ['adventure', 'fiction','religion']\n",
    "D = []\n",
    "for cat in categories:\n",
    "    D += brown.sents(categories = cat)[:10]\n",
    "T = len(categories)\n",
    "dictionary = list(set(brown.words(categories=categories)))\n",
    "print len(D), len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_estimates(estimates):\n",
    "    plt.figure(figsize = (9, 9))\n",
    "    plt.plot(estimates)\n",
    "    plt.xlabel('N iterations')\n",
    "    plt.title('Variational lower estimates')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правильное количество тем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimates, index = EM(D, T, dictionary, start_iterations = 3)\n",
    "\n",
    "plot_estimates(estimates[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большее количество тем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimates1, index1 = EM(D, T+2, dictionary, start_iterations = 3)\n",
    "\n",
    "plot_estimates(estimates1[index1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меньшее количество тем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimates2, index2 = EM(D, T-1, dictionary,start_iterations = 3)\n",
    "\n",
    "plot_estimates(estimates2[index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = np.random.randint(0, len(D)+1, size = 0.5*len(D))\n",
    "test_indices = list(set(range(len(D))).difference(set(train_indices)))\n",
    "D_train = D[train_indices]\n",
    "D_test = D[test_indices]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
